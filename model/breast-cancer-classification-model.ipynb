{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Breast Cancer Classification </center>\n",
    "\n",
    "<b>Problem statement: </b> In this project we are going to classify patients abnormal mass of cells (tumors). Tumors can either be benign (non-cancerous) or malignant (cancerous).Benign tumors are generally not harmful but if a patient is diagnosed with a malignant tumor then they should be given treatment immediately. This is a classification problem with two classes to predict. We will start with logistic regression as our model and eventually select the best model for our dataset.\n",
    "\n",
    "\n",
    "An Otsogile Ogaisitse Onalepelo aka Morena project.\n",
    "\n",
    "\n",
    "### Import the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from sklearn\n",
    "breast_cancer_dataset = sklearn.datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
      "        1.189e-01],\n",
      "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
      "        8.902e-02],\n",
      "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
      "        8.758e-02],\n",
      "       ...,\n",
      "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
      "        7.820e-02],\n",
      "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
      "        1.240e-01],\n",
      "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
      "        7.039e-02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
      "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]), 'frame': None, 'target_names': array(['malignant', 'benign'], dtype='<U9'), 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.', 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error',\n",
      "       'fractal dimension error', 'worst radius', 'worst texture',\n",
      "       'worst perimeter', 'worst area', 'worst smoothness',\n",
      "       'worst compactness', 'worst concavity', 'worst concave points',\n",
      "       'worst symmetry', 'worst fractal dimension'], dtype='<U23'), 'filename': 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}\n"
     ]
    }
   ],
   "source": [
    "print(breast_cancer_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the feature names\n",
    "breast_cancer_dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into a dataframe\n",
    "data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of the dataframe\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the 'target' column to the data frame\n",
    "data_frame['label'] = breast_cancer_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print last 5 rows of the dataframe\n",
    "data_frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of rows and columns in the dataset\n",
    "data_frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have 569 rows and 31 columns in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  label                    569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n"
     ]
    }
   ],
   "source": [
    "# getting some information about the data\n",
    "data_frame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears we do not have any missing values in our data. All our features have float64 data type other than the target feature .i.e. label which have an int32 data type. We also do not have any categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "label                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values again\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaay!ðŸ˜ƒðŸ˜ƒ We really do not have any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>0.627417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>0.483918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
       "count     569.000000              569.000000  ...     569.000000   \n",
       "mean        0.181162                0.062798  ...      25.677223   \n",
       "std         0.027414                0.007060  ...       6.146258   \n",
       "min         0.106000                0.049960  ...      12.020000   \n",
       "25%         0.161900                0.057700  ...      21.080000   \n",
       "50%         0.179200                0.061540  ...      25.410000   \n",
       "75%         0.195700                0.066120  ...      29.720000   \n",
       "max         0.304000                0.097440  ...      49.540000   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       worst fractal dimension       label  \n",
       "count               569.000000  569.000000  \n",
       "mean                  0.083946    0.627417  \n",
       "std                   0.018061    0.483918  \n",
       "min                   0.055040    0.000000  \n",
       "25%                   0.071460    0.000000  \n",
       "50%                   0.080040    1.000000  \n",
       "75%                   0.092080    1.000000  \n",
       "max                   0.207500    1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistical measures about the data\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm....The following features have very huge values while others have small values.\n",
    "\n",
    "-mean radius\n",
    "\n",
    "-mean texture\n",
    "\n",
    "-mean perimeter\n",
    "\n",
    "-mean area\n",
    "\n",
    "-worst texture\n",
    "\n",
    "-worst perimeter\n",
    "\n",
    "-worst area\n",
    "\n",
    "-area error\n",
    "\n",
    "-worst radius\n",
    "\n",
    "We are going to have to scale them in a bit so we have values in our dataset within a common range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of Target Varibale\n",
    "data_frame['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 --> Benign\n",
    "\n",
    "0 --> Malignant\n",
    "\n",
    "There is also an imbalance in our classes. We have more benign observations with 357 compared to 212 for malignant. This is another problem we have to resolve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  label  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.462830</td>\n",
       "      <td>21.604906</td>\n",
       "      <td>115.365377</td>\n",
       "      <td>978.376415</td>\n",
       "      <td>0.102898</td>\n",
       "      <td>0.145188</td>\n",
       "      <td>0.160775</td>\n",
       "      <td>0.087990</td>\n",
       "      <td>0.192909</td>\n",
       "      <td>0.062680</td>\n",
       "      <td>...</td>\n",
       "      <td>21.134811</td>\n",
       "      <td>29.318208</td>\n",
       "      <td>141.370330</td>\n",
       "      <td>1422.286321</td>\n",
       "      <td>0.144845</td>\n",
       "      <td>0.374824</td>\n",
       "      <td>0.450606</td>\n",
       "      <td>0.182237</td>\n",
       "      <td>0.323468</td>\n",
       "      <td>0.091530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.146524</td>\n",
       "      <td>17.914762</td>\n",
       "      <td>78.075406</td>\n",
       "      <td>462.790196</td>\n",
       "      <td>0.092478</td>\n",
       "      <td>0.080085</td>\n",
       "      <td>0.046058</td>\n",
       "      <td>0.025717</td>\n",
       "      <td>0.174186</td>\n",
       "      <td>0.062867</td>\n",
       "      <td>...</td>\n",
       "      <td>13.379801</td>\n",
       "      <td>23.515070</td>\n",
       "      <td>87.005938</td>\n",
       "      <td>558.899440</td>\n",
       "      <td>0.124959</td>\n",
       "      <td>0.182673</td>\n",
       "      <td>0.166238</td>\n",
       "      <td>0.074444</td>\n",
       "      <td>0.270246</td>\n",
       "      <td>0.079442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter   mean area  mean smoothness  \\\n",
       "label                                                                           \n",
       "0        17.462830     21.604906      115.365377  978.376415         0.102898   \n",
       "1        12.146524     17.914762       78.075406  462.790196         0.092478   \n",
       "\n",
       "       mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "label                                                                         \n",
       "0              0.145188        0.160775             0.087990       0.192909   \n",
       "1              0.080085        0.046058             0.025717       0.174186   \n",
       "\n",
       "       mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "label                          ...                                \n",
       "0                    0.062680  ...     21.134811      29.318208   \n",
       "1                    0.062867  ...     13.379801      23.515070   \n",
       "\n",
       "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
       "label                                                                      \n",
       "0           141.370330  1422.286321          0.144845           0.374824   \n",
       "1            87.005938   558.899440          0.124959           0.182673   \n",
       "\n",
       "       worst concavity  worst concave points  worst symmetry  \\\n",
       "label                                                          \n",
       "0             0.450606              0.182237        0.323468   \n",
       "1             0.166238              0.074444        0.270246   \n",
       "\n",
       "       worst fractal dimension  \n",
       "label                           \n",
       "0                     0.091530  \n",
       "1                     0.079442  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.groupby('label').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Feature Scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "cols_to_scale = ['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "       'smoothness error', 'compactness error', 'concavity error',\n",
    "       'concave points error', 'symmetry error',\n",
    "       'fractal dimension error', 'worst radius', 'worst texture',\n",
    "       'worst perimeter', 'worst area', 'worst smoothness',\n",
    "       'worst compactness', 'worst concavity', 'worst concave points',\n",
    "       'worst symmetry', 'worst fractal dimension']\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_frame[cols_to_scale] = scaler.fit_transform(data_frame[cols_to_scale])\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Nice!. I really love what i am looking at here..ðŸ˜. Now we have our feature values ranging from 0 to 1,some just a few points above 1 and others below but not by much. Which is better compared to how they were initially.\n",
    "\n",
    "<b>EDIT: <b/> It turns our our model actually performs better on scaled data however there is a slight hiccup. Making predictions from a React Js and React Native client turns out to be challenging. The predictions made are flawed if the data is  not scaled and when we scale user inputs another problem brews. The inputs get distorted as they are now taken as a single column not a row when scalling them. Hence, I decided to just train the model on unscaled data and to not run the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Dataset Imbalance\n",
    "\n",
    "Training a model on an imbalanced dataset might result in our model not performing as per our expectations. Therefore, before we go any further with our data preprocessing. Let us handle this imbalance first. There are various techniques we could utilize to accomplish this like, undersampling the majority class, oversampling the minority class, ensenble method and SMOTE. For this pipeline we will oversample the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random over-sampling:\n",
      "1    357\n",
      "0    357\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class count\n",
    "count_class_1, count_class_0 = data_frame.label.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = data_frame[data_frame['label'] == 0]\n",
    "df_class_1 = data_frame[data_frame['label'] == 1]\n",
    "\n",
    "# Oversample 0-class and concat the DataFrames of both classes\n",
    "df_class_0_over = df_class_0.sample(count_class_1, replace=True)\n",
    "df_test_over = pd.concat([df_class_0_over, df_class_1], axis=0)\n",
    "\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_test_over.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bravooo ðŸ‘ðŸ‘. Our classes are now perfectly balanced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection and Removal\n",
    "\n",
    "We kind of have the curse of dimensionality in this dataset therefore, using traditional and statistical outlier detection methods is slightly not practical. We will have to go over each feature and analyse it. Thus, we will use a automatic outlier detection and removal technique specifically One Class SVM.\n",
    "\n",
    "\n",
    "For more information on automatic outlier detection methods read more here: https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/. Some code used here in is kind of borrowed from there.ðŸ˜†ðŸ˜…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(499, 30) (499,)\n",
      "(324, 30) (324,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# retrieve the array\n",
    "data = df_test_over.values\n",
    "# split into input and output elements to prevent over fitting and data leakage\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "# summarize the shape of the training dataset\n",
    "print(X_train.shape, y_train.shape)\n",
    "# identify outliers in the training dataset\n",
    "#The class provides the â€œnuâ€ argument that specifies a approx ratio of outliers in the dataset, default = 0.1\n",
    "ocs = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.01)\n",
    "yhat = ocs.fit_predict(X_train)\n",
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train, y_train = X_train[mask, :], y_train[mask]\n",
    "# summarize the shape of the updated training dataset\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! So, different nu values detects and removes a different number of outliers in our dataset which might change our class value counts as well. Maybe we should have balanced the dataset after removing outliers? ðŸ¤”ðŸ¤”ðŸ¤”.Probably!! Anyhow, lets leave it as it is and proceed to feature selection.\n",
    "\n",
    "### Feature Selection\n",
    "\n",
    "We have 30 features in our dataset. Some of them might actually be very important for building our model. Therefore let us use mutual information to detect the most important features and select them for our model.\n",
    "\n",
    "\n",
    "#### Mutual Information  (MI)\n",
    "\n",
    "MI Estimate mutual information for a discrete target variable.\n",
    "\n",
    "Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency between variables.\n",
    "\n",
    "The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances.\n",
    "\n",
    "Inshort\n",
    "\n",
    "A quantity called mutual information measures the amount of information one can obtain from one random variable given another.\n",
    "\n",
    "The mutual information between two random variables X and Y can be stated formally as follows:\n",
    "\n",
    "<b>I(X ; Y) = H(X) â€“ H(X | Y)<b>\n",
    "Where I(X ; Y) is the mutual information for X and Y, H(X) is the entropy for X and H(X | Y) is the conditional entropy for X given Y. The result has the units of bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46351411, 0.21546435, 0.48162812, 0.4832702 , 0.1728233 ,\n",
       "       0.3104849 , 0.3879166 , 0.52037098, 0.19212447, 0.12486569,\n",
       "       0.35016369, 0.17141567, 0.38499358, 0.48779367, 0.16641495,\n",
       "       0.134671  , 0.20499353, 0.21923689, 0.12317525, 0.17953063,\n",
       "       0.53887921, 0.20771784, 0.53058323, 0.53254539, 0.18613407,\n",
       "       0.31408895, 0.37991203, 0.4629573 , 0.2350373 , 0.17122311])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the library that we will be using to do feature selection using mutual information for classification problems\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "# determine the mutual information\n",
    "mutual_info = mutual_info_classif(X_train, y_train)\n",
    "mutual_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the mutual info class you never get back any negative values. If you get a very high value, then it means that feature dependency on the target variable is too much and which ever features have high values are the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worst radius               0.538879\n",
       "worst area                 0.532545\n",
       "worst perimeter            0.530583\n",
       "mean concave points        0.520371\n",
       "area error                 0.487794\n",
       "mean area                  0.483270\n",
       "mean perimeter             0.481628\n",
       "mean radius                0.463514\n",
       "worst concave points       0.462957\n",
       "mean concavity             0.387917\n",
       "perimeter error            0.384994\n",
       "worst concavity            0.379912\n",
       "radius error               0.350164\n",
       "worst compactness          0.314089\n",
       "mean compactness           0.310485\n",
       "worst symmetry             0.235037\n",
       "concave points error       0.219237\n",
       "mean texture               0.215464\n",
       "worst texture              0.207718\n",
       "concavity error            0.204994\n",
       "mean symmetry              0.192124\n",
       "worst smoothness           0.186134\n",
       "fractal dimension error    0.179531\n",
       "mean smoothness            0.172823\n",
       "texture error              0.171416\n",
       "worst fractal dimension    0.171223\n",
       "smoothness error           0.166415\n",
       "compactness error          0.134671\n",
       "mean fractal dimension     0.124866\n",
       "symmetry error             0.123175\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the mutual information array into a series so we can see which value belongs to which feature.\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = breast_cancer_dataset.feature_names\n",
    "mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that worst area has the highest dependency on our target variable followed by worst perimeter etc. Its not always necessary that you should take all the features for your model. You can take the top 10 or 20 features and drop others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x234e1e597c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#let's plot the ordered mutual_info values per feature\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean compactness', 'mean concavity', 'mean concave points',\n",
       "       'radius error', 'perimeter error', 'area error', 'concavity error',\n",
       "       'concave points error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst compactness',\n",
       "       'worst concavity', 'worst concave points', 'worst symmetry'],\n",
       "      dtype='<U23')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this module allows us to select our desired features per the percentage or criteria we want e.g. top 10, top 10%, top 10 percentile of the features etc\n",
    "#this is also usually determied by the number of features in our dataset\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "#Now we Will select the  top 20 features\n",
    "#To avoid overfitting and data leak. We only do this process for X  and y Train\n",
    "sel_twenty_cols = SelectKBest(mutual_info_classif, k=20)\n",
    "sel_twenty_cols.fit(X_train, y_train)\n",
    "#display the top 20features we can use for our model building\n",
    "breast_cancer_dataset.feature_names[sel_twenty_cols.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_twenty_features = breast_cancer_dataset.feature_names[sel_twenty_cols.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean compactness', 'mean concavity', 'mean concave points',\n",
       "       'radius error', 'perimeter error', 'area error', 'concavity error',\n",
       "       'concave points error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst compactness',\n",
       "       'worst concavity', 'worst concave points', 'worst symmetry'],\n",
       "      dtype='<U23')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_twenty_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put X_train and X_test back into dataframes for feature selection\n",
    "X_train_df =pd.DataFrame(X_train,columns=breast_cancer_dataset.feature_names)\n",
    "X_test_df =pd.DataFrame(X_test,columns=breast_cancer_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the X_train and X_test above because we have already removed outliers from the main data frame, it will be a step back if we used it as we will have to remove ourliers again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.350</td>\n",
       "      <td>23.29</td>\n",
       "      <td>109.00</td>\n",
       "      <td>840.4</td>\n",
       "      <td>0.09742</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>0.18110</td>\n",
       "      <td>0.08773</td>\n",
       "      <td>0.2175</td>\n",
       "      <td>0.06218</td>\n",
       "      <td>...</td>\n",
       "      <td>19.38</td>\n",
       "      <td>31.03</td>\n",
       "      <td>129.30</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.4665</td>\n",
       "      <td>0.70870</td>\n",
       "      <td>0.22480</td>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.09614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.210</td>\n",
       "      <td>14.09</td>\n",
       "      <td>78.78</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.08108</td>\n",
       "      <td>0.07823</td>\n",
       "      <td>0.06839</td>\n",
       "      <td>0.02534</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>...</td>\n",
       "      <td>13.13</td>\n",
       "      <td>19.29</td>\n",
       "      <td>87.65</td>\n",
       "      <td>529.9</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.30760</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.430</td>\n",
       "      <td>15.39</td>\n",
       "      <td>73.06</td>\n",
       "      <td>399.8</td>\n",
       "      <td>0.09639</td>\n",
       "      <td>0.06889</td>\n",
       "      <td>0.03503</td>\n",
       "      <td>0.02875</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>0.05865</td>\n",
       "      <td>...</td>\n",
       "      <td>12.32</td>\n",
       "      <td>22.02</td>\n",
       "      <td>79.93</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.13990</td>\n",
       "      <td>0.08476</td>\n",
       "      <td>0.2676</td>\n",
       "      <td>0.06765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.210</td>\n",
       "      <td>25.25</td>\n",
       "      <td>84.10</td>\n",
       "      <td>537.9</td>\n",
       "      <td>0.08791</td>\n",
       "      <td>0.05205</td>\n",
       "      <td>0.02772</td>\n",
       "      <td>0.02068</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.05584</td>\n",
       "      <td>...</td>\n",
       "      <td>14.35</td>\n",
       "      <td>34.23</td>\n",
       "      <td>91.29</td>\n",
       "      <td>632.9</td>\n",
       "      <td>0.1289</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.06005</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.06788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>12.720</td>\n",
       "      <td>13.78</td>\n",
       "      <td>81.78</td>\n",
       "      <td>492.1</td>\n",
       "      <td>0.09667</td>\n",
       "      <td>0.08393</td>\n",
       "      <td>0.01288</td>\n",
       "      <td>0.01924</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.06100</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>17.48</td>\n",
       "      <td>88.54</td>\n",
       "      <td>553.7</td>\n",
       "      <td>0.1298</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>0.2369</td>\n",
       "      <td>0.06922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>9.904</td>\n",
       "      <td>18.06</td>\n",
       "      <td>64.60</td>\n",
       "      <td>302.4</td>\n",
       "      <td>0.09699</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.13070</td>\n",
       "      <td>0.03716</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.08116</td>\n",
       "      <td>...</td>\n",
       "      <td>11.26</td>\n",
       "      <td>24.39</td>\n",
       "      <td>73.07</td>\n",
       "      <td>390.2</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.34860</td>\n",
       "      <td>0.09910</td>\n",
       "      <td>0.2614</td>\n",
       "      <td>0.11620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>12.630</td>\n",
       "      <td>20.76</td>\n",
       "      <td>82.15</td>\n",
       "      <td>480.4</td>\n",
       "      <td>0.09933</td>\n",
       "      <td>0.12090</td>\n",
       "      <td>0.10650</td>\n",
       "      <td>0.06021</td>\n",
       "      <td>0.1735</td>\n",
       "      <td>0.07070</td>\n",
       "      <td>...</td>\n",
       "      <td>13.33</td>\n",
       "      <td>25.47</td>\n",
       "      <td>89.00</td>\n",
       "      <td>527.4</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.08486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>14.220</td>\n",
       "      <td>23.12</td>\n",
       "      <td>94.37</td>\n",
       "      <td>609.9</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.24130</td>\n",
       "      <td>0.19810</td>\n",
       "      <td>0.06618</td>\n",
       "      <td>0.2384</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>...</td>\n",
       "      <td>15.74</td>\n",
       "      <td>37.18</td>\n",
       "      <td>106.40</td>\n",
       "      <td>762.4</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.84880</td>\n",
       "      <td>0.17720</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.14460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>12.320</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0         19.170         24.80          132.40     1123.0          0.09740   \n",
       "1         16.350         23.29          109.00      840.4          0.09742   \n",
       "2         12.210         14.09           78.78      462.0          0.08108   \n",
       "3         11.430         15.39           73.06      399.8          0.09639   \n",
       "4         13.210         25.25           84.10      537.9          0.08791   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "319       12.720         13.78           81.78      492.1          0.09667   \n",
       "320        9.904         18.06           64.60      302.4          0.09699   \n",
       "321       12.630         20.76           82.15      480.4          0.09933   \n",
       "322       14.220         23.12           94.37      609.9          0.10750   \n",
       "323       12.320         12.39           78.85      464.1          0.10280   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.24580         0.20650              0.11180         0.2397   \n",
       "1             0.14970         0.18110              0.08773         0.2175   \n",
       "2             0.07823         0.06839              0.02534         0.1646   \n",
       "3             0.06889         0.03503              0.02875         0.1734   \n",
       "4             0.05205         0.02772              0.02068         0.1619   \n",
       "..                ...             ...                  ...            ...   \n",
       "319           0.08393         0.01288              0.01924         0.1638   \n",
       "320           0.12940         0.13070              0.03716         0.1669   \n",
       "321           0.12090         0.10650              0.06021         0.1735   \n",
       "322           0.24130         0.19810              0.06618         0.2384   \n",
       "323           0.06981         0.03987              0.03700         0.1959   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07800  ...         20.96          29.94   \n",
       "1                   0.06218  ...         19.38          31.03   \n",
       "2                   0.06154  ...         13.13          19.29   \n",
       "3                   0.05865  ...         12.32          22.02   \n",
       "4                   0.05584  ...         14.35          34.23   \n",
       "..                      ...  ...           ...            ...   \n",
       "319                 0.06100  ...         13.50          17.48   \n",
       "320                 0.08116  ...         11.26          24.39   \n",
       "321                 0.07070  ...         13.33          25.47   \n",
       "322                 0.07542  ...         15.74          37.18   \n",
       "323                 0.05955  ...         13.50          15.64   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             151.70      1332.0            0.1037             0.3903   \n",
       "1             129.30      1165.0            0.1415             0.4665   \n",
       "2              87.65       529.9            0.1026             0.2431   \n",
       "3              79.93       462.0            0.1190             0.1648   \n",
       "4              91.29       632.9            0.1289             0.1063   \n",
       "..               ...         ...               ...                ...   \n",
       "319            88.54       553.7            0.1298             0.1472   \n",
       "320            73.07       390.2            0.1301             0.2950   \n",
       "321            89.00       527.4            0.1287             0.2250   \n",
       "322           106.40       762.4            0.1533             0.9327   \n",
       "323            86.97       549.1            0.1385             0.1266   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0            0.36390               0.17670          0.3176   \n",
       "1            0.70870               0.22480          0.4824   \n",
       "2            0.30760               0.09140          0.2677   \n",
       "3            0.13990               0.08476          0.2676   \n",
       "4            0.13900               0.06005          0.2444   \n",
       "..               ...                   ...             ...   \n",
       "319          0.05233               0.06343          0.2369   \n",
       "320          0.34860               0.09910          0.2614   \n",
       "321          0.22160               0.11050          0.2226   \n",
       "322          0.84880               0.17720          0.5166   \n",
       "323          0.12420               0.09391          0.2827   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.10230  \n",
       "1                    0.09614  \n",
       "2                    0.08824  \n",
       "3                    0.06765  \n",
       "4                    0.06788  \n",
       "..                       ...  \n",
       "319                  0.06922  \n",
       "320                  0.11620  \n",
       "321                  0.08486  \n",
       "322                  0.14460  \n",
       "323                  0.06771  \n",
       "\n",
       "[324 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>0.06171</td>\n",
       "      <td>...</td>\n",
       "      <td>15.30</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.12410</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.270</td>\n",
       "      <td>19.67</td>\n",
       "      <td>152.80</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.27680</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>...</td>\n",
       "      <td>28.40</td>\n",
       "      <td>28.01</td>\n",
       "      <td>206.80</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>0.17010</td>\n",
       "      <td>0.69970</td>\n",
       "      <td>0.960800</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>0.09789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.650</td>\n",
       "      <td>18.17</td>\n",
       "      <td>82.69</td>\n",
       "      <td>485.6</td>\n",
       "      <td>0.10760</td>\n",
       "      <td>0.13340</td>\n",
       "      <td>0.080170</td>\n",
       "      <td>0.050740</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.06854</td>\n",
       "      <td>...</td>\n",
       "      <td>14.38</td>\n",
       "      <td>22.15</td>\n",
       "      <td>95.29</td>\n",
       "      <td>633.7</td>\n",
       "      <td>0.15330</td>\n",
       "      <td>0.38420</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.3230</td>\n",
       "      <td>0.10330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.940</td>\n",
       "      <td>18.59</td>\n",
       "      <td>70.39</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.10040</td>\n",
       "      <td>0.07460</td>\n",
       "      <td>0.049440</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0.06615</td>\n",
       "      <td>...</td>\n",
       "      <td>12.40</td>\n",
       "      <td>25.58</td>\n",
       "      <td>82.76</td>\n",
       "      <td>472.4</td>\n",
       "      <td>0.13630</td>\n",
       "      <td>0.16440</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.078870</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.07732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.310</td>\n",
       "      <td>27.06</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.10880</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.093330</td>\n",
       "      <td>0.1814</td>\n",
       "      <td>0.05572</td>\n",
       "      <td>...</td>\n",
       "      <td>24.33</td>\n",
       "      <td>39.16</td>\n",
       "      <td>162.30</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>0.15220</td>\n",
       "      <td>0.29450</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.3151</td>\n",
       "      <td>0.07999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>21.750</td>\n",
       "      <td>20.99</td>\n",
       "      <td>147.30</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>0.09401</td>\n",
       "      <td>0.19610</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.06194</td>\n",
       "      <td>...</td>\n",
       "      <td>28.19</td>\n",
       "      <td>28.18</td>\n",
       "      <td>195.90</td>\n",
       "      <td>2384.0</td>\n",
       "      <td>0.12720</td>\n",
       "      <td>0.47250</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.2833</td>\n",
       "      <td>0.08858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>9.676</td>\n",
       "      <td>13.14</td>\n",
       "      <td>64.12</td>\n",
       "      <td>272.5</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.22040</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.070380</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.09575</td>\n",
       "      <td>...</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.04</td>\n",
       "      <td>69.47</td>\n",
       "      <td>328.1</td>\n",
       "      <td>0.20060</td>\n",
       "      <td>0.36630</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.2848</td>\n",
       "      <td>0.13640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>13.010</td>\n",
       "      <td>22.22</td>\n",
       "      <td>82.01</td>\n",
       "      <td>526.4</td>\n",
       "      <td>0.06251</td>\n",
       "      <td>0.01938</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>0.05234</td>\n",
       "      <td>...</td>\n",
       "      <td>14.00</td>\n",
       "      <td>29.02</td>\n",
       "      <td>88.18</td>\n",
       "      <td>608.8</td>\n",
       "      <td>0.08125</td>\n",
       "      <td>0.03432</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.2295</td>\n",
       "      <td>0.05843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>13.000</td>\n",
       "      <td>25.13</td>\n",
       "      <td>82.61</td>\n",
       "      <td>520.2</td>\n",
       "      <td>0.08369</td>\n",
       "      <td>0.05073</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.05449</td>\n",
       "      <td>...</td>\n",
       "      <td>14.34</td>\n",
       "      <td>31.88</td>\n",
       "      <td>91.06</td>\n",
       "      <td>628.5</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.10930</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.059210</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.06291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>11.840</td>\n",
       "      <td>18.70</td>\n",
       "      <td>77.93</td>\n",
       "      <td>440.6</td>\n",
       "      <td>0.11090</td>\n",
       "      <td>0.15160</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.051820</td>\n",
       "      <td>0.2301</td>\n",
       "      <td>0.07799</td>\n",
       "      <td>...</td>\n",
       "      <td>16.82</td>\n",
       "      <td>28.12</td>\n",
       "      <td>119.40</td>\n",
       "      <td>888.7</td>\n",
       "      <td>0.16370</td>\n",
       "      <td>0.57750</td>\n",
       "      <td>0.695600</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.4761</td>\n",
       "      <td>0.14020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0         14.050         27.15           91.38      600.4          0.09929   \n",
       "1         22.270         19.67          152.80     1509.0          0.13260   \n",
       "2         12.650         18.17           82.69      485.6          0.10760   \n",
       "3         10.940         18.59           70.39      370.0          0.10040   \n",
       "4         20.310         27.06          132.90     1288.0          0.10000   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "210       21.750         20.99          147.30     1491.0          0.09401   \n",
       "211        9.676         13.14           64.12      272.5          0.12550   \n",
       "212       13.010         22.22           82.01      526.4          0.06251   \n",
       "213       13.000         25.13           82.61      520.2          0.08369   \n",
       "214       11.840         18.70           77.93      440.6          0.11090   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.11260        0.044620             0.043040         0.1537   \n",
       "1             0.27680        0.426400             0.182300         0.2556   \n",
       "2             0.13340        0.080170             0.050740         0.1641   \n",
       "3             0.07460        0.049440             0.029320         0.1486   \n",
       "4             0.10880        0.151900             0.093330         0.1814   \n",
       "..                ...             ...                  ...            ...   \n",
       "210           0.19610        0.219500             0.108800         0.1721   \n",
       "211           0.22040        0.118800             0.070380         0.2057   \n",
       "212           0.01938        0.001595             0.001852         0.1395   \n",
       "213           0.05073        0.012060             0.017620         0.1667   \n",
       "214           0.15160        0.121800             0.051820         0.2301   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.06171  ...         15.30          33.17   \n",
       "1                   0.07039  ...         28.40          28.01   \n",
       "2                   0.06854  ...         14.38          22.15   \n",
       "3                   0.06615  ...         12.40          25.58   \n",
       "4                   0.05572  ...         24.33          39.16   \n",
       "..                      ...  ...           ...            ...   \n",
       "210                 0.06194  ...         28.19          28.18   \n",
       "211                 0.09575  ...         10.60          18.04   \n",
       "212                 0.05234  ...         14.00          29.02   \n",
       "213                 0.05449  ...         14.34          31.88   \n",
       "214                 0.07799  ...         16.82          28.12   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             100.20       706.7           0.12410            0.22640   \n",
       "1             206.80      2360.0           0.17010            0.69970   \n",
       "2              95.29       633.7           0.15330            0.38420   \n",
       "3              82.76       472.4           0.13630            0.16440   \n",
       "4             162.30      1844.0           0.15220            0.29450   \n",
       "..               ...         ...               ...                ...   \n",
       "210           195.90      2384.0           0.12720            0.47250   \n",
       "211            69.47       328.1           0.20060            0.36630   \n",
       "212            88.18       608.8           0.08125            0.03432   \n",
       "213            91.06       628.5           0.12180            0.10930   \n",
       "214           119.40       888.7           0.16370            0.57750   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0           0.132600              0.104800          0.2250   \n",
       "1           0.960800              0.291000          0.4055   \n",
       "2           0.358200              0.140700          0.3230   \n",
       "3           0.141200              0.078870          0.2251   \n",
       "4           0.378800              0.169700          0.3151   \n",
       "..               ...                   ...             ...   \n",
       "210         0.580700              0.184100          0.2833   \n",
       "211         0.291300              0.107500          0.2848   \n",
       "212         0.007977              0.009259          0.2295   \n",
       "213         0.044620              0.059210          0.2306   \n",
       "214         0.695600              0.154600          0.4761   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.08321  \n",
       "1                    0.09789  \n",
       "2                    0.10330  \n",
       "3                    0.07732  \n",
       "4                    0.07999  \n",
       "..                       ...  \n",
       "210                  0.08858  \n",
       "211                  0.13640  \n",
       "212                  0.05843  \n",
       "213                  0.06291  \n",
       "214                  0.14020  \n",
       "\n",
       "[215 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unmportant features for both X Train and X Test.\n",
    "X_train_df = X_train_df[top_twenty_features]\n",
    "X_test_df = X_test_df[top_twenty_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>radius error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.170</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>11.070</td>\n",
       "      <td>116.20</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.36390</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.350</td>\n",
       "      <td>23.29</td>\n",
       "      <td>109.00</td>\n",
       "      <td>840.4</td>\n",
       "      <td>0.14970</td>\n",
       "      <td>0.18110</td>\n",
       "      <td>0.08773</td>\n",
       "      <td>0.4312</td>\n",
       "      <td>2.972</td>\n",
       "      <td>45.50</td>\n",
       "      <td>0.060720</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>19.38</td>\n",
       "      <td>31.03</td>\n",
       "      <td>129.30</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0.4665</td>\n",
       "      <td>0.70870</td>\n",
       "      <td>0.22480</td>\n",
       "      <td>0.4824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.210</td>\n",
       "      <td>14.09</td>\n",
       "      <td>78.78</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.07823</td>\n",
       "      <td>0.06839</td>\n",
       "      <td>0.02534</td>\n",
       "      <td>0.2666</td>\n",
       "      <td>2.097</td>\n",
       "      <td>19.96</td>\n",
       "      <td>0.043440</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>13.13</td>\n",
       "      <td>19.29</td>\n",
       "      <td>87.65</td>\n",
       "      <td>529.9</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.30760</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.2677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.430</td>\n",
       "      <td>15.39</td>\n",
       "      <td>73.06</td>\n",
       "      <td>399.8</td>\n",
       "      <td>0.06889</td>\n",
       "      <td>0.03503</td>\n",
       "      <td>0.02875</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>1.143</td>\n",
       "      <td>12.67</td>\n",
       "      <td>0.014340</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>12.32</td>\n",
       "      <td>22.02</td>\n",
       "      <td>79.93</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.13990</td>\n",
       "      <td>0.08476</td>\n",
       "      <td>0.2676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.210</td>\n",
       "      <td>25.25</td>\n",
       "      <td>84.10</td>\n",
       "      <td>537.9</td>\n",
       "      <td>0.05205</td>\n",
       "      <td>0.02772</td>\n",
       "      <td>0.02068</td>\n",
       "      <td>0.2084</td>\n",
       "      <td>1.314</td>\n",
       "      <td>17.58</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>14.35</td>\n",
       "      <td>34.23</td>\n",
       "      <td>91.29</td>\n",
       "      <td>632.9</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.13900</td>\n",
       "      <td>0.06005</td>\n",
       "      <td>0.2444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>12.720</td>\n",
       "      <td>13.78</td>\n",
       "      <td>81.78</td>\n",
       "      <td>492.1</td>\n",
       "      <td>0.08393</td>\n",
       "      <td>0.01288</td>\n",
       "      <td>0.01924</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>1.340</td>\n",
       "      <td>13.38</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.007978</td>\n",
       "      <td>13.50</td>\n",
       "      <td>17.48</td>\n",
       "      <td>88.54</td>\n",
       "      <td>553.7</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>0.2369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>9.904</td>\n",
       "      <td>18.06</td>\n",
       "      <td>64.60</td>\n",
       "      <td>302.4</td>\n",
       "      <td>0.12940</td>\n",
       "      <td>0.13070</td>\n",
       "      <td>0.03716</td>\n",
       "      <td>0.4311</td>\n",
       "      <td>3.132</td>\n",
       "      <td>27.48</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>11.26</td>\n",
       "      <td>24.39</td>\n",
       "      <td>73.07</td>\n",
       "      <td>390.2</td>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.34860</td>\n",
       "      <td>0.09910</td>\n",
       "      <td>0.2614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>12.630</td>\n",
       "      <td>20.76</td>\n",
       "      <td>82.15</td>\n",
       "      <td>480.4</td>\n",
       "      <td>0.12090</td>\n",
       "      <td>0.10650</td>\n",
       "      <td>0.06021</td>\n",
       "      <td>0.3424</td>\n",
       "      <td>2.711</td>\n",
       "      <td>20.48</td>\n",
       "      <td>0.051010</td>\n",
       "      <td>0.022950</td>\n",
       "      <td>13.33</td>\n",
       "      <td>25.47</td>\n",
       "      <td>89.00</td>\n",
       "      <td>527.4</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.22160</td>\n",
       "      <td>0.11050</td>\n",
       "      <td>0.2226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>14.220</td>\n",
       "      <td>23.12</td>\n",
       "      <td>94.37</td>\n",
       "      <td>609.9</td>\n",
       "      <td>0.24130</td>\n",
       "      <td>0.19810</td>\n",
       "      <td>0.06618</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>2.112</td>\n",
       "      <td>31.72</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.016660</td>\n",
       "      <td>15.74</td>\n",
       "      <td>37.18</td>\n",
       "      <td>106.40</td>\n",
       "      <td>762.4</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.84880</td>\n",
       "      <td>0.17720</td>\n",
       "      <td>0.5166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>12.320</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>1.670</td>\n",
       "      <td>17.43</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean compactness  \\\n",
       "0         19.170         24.80          132.40     1123.0           0.24580   \n",
       "1         16.350         23.29          109.00      840.4           0.14970   \n",
       "2         12.210         14.09           78.78      462.0           0.07823   \n",
       "3         11.430         15.39           73.06      399.8           0.06889   \n",
       "4         13.210         25.25           84.10      537.9           0.05205   \n",
       "..           ...           ...             ...        ...               ...   \n",
       "319       12.720         13.78           81.78      492.1           0.08393   \n",
       "320        9.904         18.06           64.60      302.4           0.12940   \n",
       "321       12.630         20.76           82.15      480.4           0.12090   \n",
       "322       14.220         23.12           94.37      609.9           0.24130   \n",
       "323       12.320         12.39           78.85      464.1           0.06981   \n",
       "\n",
       "     mean concavity  mean concave points  radius error  perimeter error  \\\n",
       "0           0.20650              0.11180        0.9555           11.070   \n",
       "1           0.18110              0.08773        0.4312            2.972   \n",
       "2           0.06839              0.02534        0.2666            2.097   \n",
       "3           0.03503              0.02875        0.1759            1.143   \n",
       "4           0.02772              0.02068        0.2084            1.314   \n",
       "..              ...                  ...           ...              ...   \n",
       "319         0.01288              0.01924        0.1807            1.340   \n",
       "320         0.13070              0.03716        0.4311            3.132   \n",
       "321         0.10650              0.06021        0.3424            2.711   \n",
       "322         0.19810              0.06618        0.2860            2.112   \n",
       "323         0.03987              0.03700        0.2360            1.670   \n",
       "\n",
       "     area error  concavity error  concave points error  worst radius  \\\n",
       "0        116.20         0.088900              0.040900         20.96   \n",
       "1         45.50         0.060720              0.016560         19.38   \n",
       "2         19.96         0.043440              0.010870         13.13   \n",
       "3         12.67         0.014340              0.008602         12.32   \n",
       "4         17.58         0.015100              0.006451         14.35   \n",
       "..          ...              ...                   ...           ...   \n",
       "319       13.38         0.006564              0.007978         13.50   \n",
       "320       27.48         0.119700              0.024600         11.26   \n",
       "321       20.48         0.051010              0.022950         13.33   \n",
       "322       31.72         0.116600              0.016660         15.74   \n",
       "323       17.43         0.016830              0.012410         13.50   \n",
       "\n",
       "     worst texture  worst perimeter  worst area  worst compactness  \\\n",
       "0            29.94           151.70      1332.0             0.3903   \n",
       "1            31.03           129.30      1165.0             0.4665   \n",
       "2            19.29            87.65       529.9             0.2431   \n",
       "3            22.02            79.93       462.0             0.1648   \n",
       "4            34.23            91.29       632.9             0.1063   \n",
       "..             ...              ...         ...                ...   \n",
       "319          17.48            88.54       553.7             0.1472   \n",
       "320          24.39            73.07       390.2             0.2950   \n",
       "321          25.47            89.00       527.4             0.2250   \n",
       "322          37.18           106.40       762.4             0.9327   \n",
       "323          15.64            86.97       549.1             0.1266   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \n",
       "0            0.36390               0.17670          0.3176  \n",
       "1            0.70870               0.22480          0.4824  \n",
       "2            0.30760               0.09140          0.2677  \n",
       "3            0.13990               0.08476          0.2676  \n",
       "4            0.13900               0.06005          0.2444  \n",
       "..               ...                   ...             ...  \n",
       "319          0.05233               0.06343          0.2369  \n",
       "320          0.34860               0.09910          0.2614  \n",
       "321          0.22160               0.11050          0.2226  \n",
       "322          0.84880               0.17720          0.5166  \n",
       "323          0.12420               0.09391          0.2827  \n",
       "\n",
       "[324 rows x 20 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>radius error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.050</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>2.888</td>\n",
       "      <td>29.84</td>\n",
       "      <td>0.020710</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>15.30</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.104800</td>\n",
       "      <td>0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.270</td>\n",
       "      <td>19.67</td>\n",
       "      <td>152.80</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>0.27680</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.182300</td>\n",
       "      <td>1.2150</td>\n",
       "      <td>10.050</td>\n",
       "      <td>170.00</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>28.40</td>\n",
       "      <td>28.01</td>\n",
       "      <td>206.80</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>0.69970</td>\n",
       "      <td>0.960800</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.650</td>\n",
       "      <td>18.17</td>\n",
       "      <td>82.69</td>\n",
       "      <td>485.6</td>\n",
       "      <td>0.13340</td>\n",
       "      <td>0.080170</td>\n",
       "      <td>0.050740</td>\n",
       "      <td>0.2324</td>\n",
       "      <td>1.696</td>\n",
       "      <td>18.40</td>\n",
       "      <td>0.026360</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>14.38</td>\n",
       "      <td>22.15</td>\n",
       "      <td>95.29</td>\n",
       "      <td>633.7</td>\n",
       "      <td>0.38420</td>\n",
       "      <td>0.358200</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.3230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.940</td>\n",
       "      <td>18.59</td>\n",
       "      <td>70.39</td>\n",
       "      <td>370.0</td>\n",
       "      <td>0.07460</td>\n",
       "      <td>0.049440</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>0.3796</td>\n",
       "      <td>3.018</td>\n",
       "      <td>25.78</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.011550</td>\n",
       "      <td>12.40</td>\n",
       "      <td>25.58</td>\n",
       "      <td>82.76</td>\n",
       "      <td>472.4</td>\n",
       "      <td>0.16440</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.078870</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.310</td>\n",
       "      <td>27.06</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>0.10880</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.093330</td>\n",
       "      <td>0.3977</td>\n",
       "      <td>2.587</td>\n",
       "      <td>52.34</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>24.33</td>\n",
       "      <td>39.16</td>\n",
       "      <td>162.30</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>0.29450</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.3151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>21.750</td>\n",
       "      <td>20.99</td>\n",
       "      <td>147.30</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>0.19610</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>1.1670</td>\n",
       "      <td>8.867</td>\n",
       "      <td>156.80</td>\n",
       "      <td>0.063290</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>28.19</td>\n",
       "      <td>28.18</td>\n",
       "      <td>195.90</td>\n",
       "      <td>2384.0</td>\n",
       "      <td>0.47250</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>9.676</td>\n",
       "      <td>13.14</td>\n",
       "      <td>64.12</td>\n",
       "      <td>272.5</td>\n",
       "      <td>0.22040</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.070380</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>1.787</td>\n",
       "      <td>17.67</td>\n",
       "      <td>0.051890</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.04</td>\n",
       "      <td>69.47</td>\n",
       "      <td>328.1</td>\n",
       "      <td>0.36630</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.2848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>13.010</td>\n",
       "      <td>22.22</td>\n",
       "      <td>82.01</td>\n",
       "      <td>526.4</td>\n",
       "      <td>0.01938</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.1731</td>\n",
       "      <td>1.101</td>\n",
       "      <td>14.34</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>14.00</td>\n",
       "      <td>29.02</td>\n",
       "      <td>88.18</td>\n",
       "      <td>608.8</td>\n",
       "      <td>0.03432</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.2295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>13.000</td>\n",
       "      <td>25.13</td>\n",
       "      <td>82.61</td>\n",
       "      <td>520.2</td>\n",
       "      <td>0.05073</td>\n",
       "      <td>0.012060</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>0.2621</td>\n",
       "      <td>1.657</td>\n",
       "      <td>21.19</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>14.34</td>\n",
       "      <td>31.88</td>\n",
       "      <td>91.06</td>\n",
       "      <td>628.5</td>\n",
       "      <td>0.10930</td>\n",
       "      <td>0.044620</td>\n",
       "      <td>0.059210</td>\n",
       "      <td>0.2306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>11.840</td>\n",
       "      <td>18.70</td>\n",
       "      <td>77.93</td>\n",
       "      <td>440.6</td>\n",
       "      <td>0.15160</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.051820</td>\n",
       "      <td>0.4825</td>\n",
       "      <td>3.475</td>\n",
       "      <td>41.00</td>\n",
       "      <td>0.042050</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>16.82</td>\n",
       "      <td>28.12</td>\n",
       "      <td>119.40</td>\n",
       "      <td>888.7</td>\n",
       "      <td>0.57750</td>\n",
       "      <td>0.695600</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.4761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean compactness  \\\n",
       "0         14.050         27.15           91.38      600.4           0.11260   \n",
       "1         22.270         19.67          152.80     1509.0           0.27680   \n",
       "2         12.650         18.17           82.69      485.6           0.13340   \n",
       "3         10.940         18.59           70.39      370.0           0.07460   \n",
       "4         20.310         27.06          132.90     1288.0           0.10880   \n",
       "..           ...           ...             ...        ...               ...   \n",
       "210       21.750         20.99          147.30     1491.0           0.19610   \n",
       "211        9.676         13.14           64.12      272.5           0.22040   \n",
       "212       13.010         22.22           82.01      526.4           0.01938   \n",
       "213       13.000         25.13           82.61      520.2           0.05073   \n",
       "214       11.840         18.70           77.93      440.6           0.15160   \n",
       "\n",
       "     mean concavity  mean concave points  radius error  perimeter error  \\\n",
       "0          0.044620             0.043040        0.3645            2.888   \n",
       "1          0.426400             0.182300        1.2150           10.050   \n",
       "2          0.080170             0.050740        0.2324            1.696   \n",
       "3          0.049440             0.029320        0.3796            3.018   \n",
       "4          0.151900             0.093330        0.3977            2.587   \n",
       "..              ...                  ...           ...              ...   \n",
       "210        0.219500             0.108800        1.1670            8.867   \n",
       "211        0.118800             0.070380        0.2744            1.787   \n",
       "212        0.001595             0.001852        0.1731            1.101   \n",
       "213        0.012060             0.017620        0.2621            1.657   \n",
       "214        0.121800             0.051820        0.4825            3.475   \n",
       "\n",
       "     area error  concavity error  concave points error  worst radius  \\\n",
       "0         29.84         0.020710              0.016260         15.30   \n",
       "1        170.00         0.104000              0.024800         28.40   \n",
       "2         18.40         0.026360              0.010320         14.38   \n",
       "3         25.78         0.019900              0.011550         12.40   \n",
       "4         52.34         0.021170              0.008185         24.33   \n",
       "..          ...              ...                   ...           ...   \n",
       "210      156.80         0.063290              0.015610         28.19   \n",
       "211       17.67         0.051890              0.014500         10.60   \n",
       "212       14.34         0.001595              0.001852         14.00   \n",
       "213       21.19         0.005681              0.006336         14.34   \n",
       "214       41.00         0.042050              0.010440         16.82   \n",
       "\n",
       "     worst texture  worst perimeter  worst area  worst compactness  \\\n",
       "0            33.17           100.20       706.7            0.22640   \n",
       "1            28.01           206.80      2360.0            0.69970   \n",
       "2            22.15            95.29       633.7            0.38420   \n",
       "3            25.58            82.76       472.4            0.16440   \n",
       "4            39.16           162.30      1844.0            0.29450   \n",
       "..             ...              ...         ...                ...   \n",
       "210          28.18           195.90      2384.0            0.47250   \n",
       "211          18.04            69.47       328.1            0.36630   \n",
       "212          29.02            88.18       608.8            0.03432   \n",
       "213          31.88            91.06       628.5            0.10930   \n",
       "214          28.12           119.40       888.7            0.57750   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \n",
       "0           0.132600              0.104800          0.2250  \n",
       "1           0.960800              0.291000          0.4055  \n",
       "2           0.358200              0.140700          0.3230  \n",
       "3           0.141200              0.078870          0.2251  \n",
       "4           0.378800              0.169700          0.3151  \n",
       "..               ...                   ...             ...  \n",
       "210         0.580700              0.184100          0.2833  \n",
       "211         0.291300              0.107500          0.2848  \n",
       "212         0.007977              0.009259          0.2295  \n",
       "213         0.044620              0.059210          0.2306  \n",
       "214         0.695600              0.154600          0.4761  \n",
       "\n",
       "[215 rows x 20 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the final x train and x test values\n",
    "X_train_final = X_train_df.values\n",
    "X_test_final = X_test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright. The numbers add up just fine ðŸ‘Œ......Next up is model building ðŸ˜Ž\n",
    "\n",
    "\n",
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=5000)\n",
    "\n",
    "#training the Logistic Regression model using Training data\n",
    "\n",
    "model.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data =  0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "# accuracy on training data\n",
    "X_train_prediction = model.predict(X_train_final)\n",
    "training_data_accuracy = accuracy_score(y_train, X_train_prediction)\n",
    "print('Accuracy on training data = ', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data =  0.9627906976744186\n"
     ]
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "X_test_prediction = model.predict(X_test_final)\n",
    "test_data_accuracy = accuracy_score(y_test, X_test_prediction)\n",
    "print('Accuracy on test data = ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use K Fold cross validation to measure accuracy of our Logistic Regression model\n",
    "\n",
    "This is just for comparison purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96503497, 0.95104895, 0.95804196, 0.96503497, 0.92307692])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit #it randomizes  our samples to ensure each fold has equal distribution\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LogisticRegression(max_iter=5000), X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9524475524475525"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the mean score for all the predictions the model made\n",
    "cross_val_score(LogisticRegression(max_iter=5000), X, y, cv=cv).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, even cross validation yields simillar accuracy scores for our model. Note that for cross validation we did not use X_train and X_test which had our top 20 features rather we used all the features the dataset has. This is solely for comparison purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization & Best Model Selection\n",
    "\n",
    "\n",
    "#### RandomizedSearchCV\n",
    "We typically use RandomizedSearchCV to reduce number of iterations and with random combination of parameters. This is useful when you have too many parameters to try and your training time is longer. It helps reduce the cost of computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.948173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.952369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.949591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_C  mean_test_score\n",
       "0       1         0.948173\n",
       "1       5         0.952369\n",
       "2      10         0.949591"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rs = RandomizedSearchCV(LogisticRegression(solver='liblinear',multi_class='auto'), {\n",
    "        'C': [1,5,10]\n",
    "    }, \n",
    "    cv=5, \n",
    "    return_train_score=False, \n",
    "    n_iter=3\n",
    ")\n",
    "rs.fit(X, y)\n",
    "pd.DataFrame(rs.cv_results_)[['param_C','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that our model can perform slightly better when we set the C parameter to 5 or 10 but how do about different models with different hyperparameters perform? Lets find out below.\n",
    "\n",
    "\n",
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',random_state=42),\n",
    "        'params' : {\n",
    "            'C': [1,10,20],\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params' : {\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'decision_tree' : {\n",
    "        'model': DecisionTreeClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'criterion': ['entropy','gini'],\n",
    "            'splitter' : ['best','random']\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "          'model': LogisticRegression(solver='liblinear',multi_class='auto',random_state=42),\n",
    "          'params': {\n",
    "              'C': [1,5,10]\n",
    "          }\n",
    "      }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.952379</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.983177</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.967753</td>\n",
       "      <td>{'criterion': 'gini', 'splitter': 'best'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.952369</td>\n",
       "      <td>{'C': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score                                best_params\n",
       "0                  svm    0.952379              {'C': 10, 'kernel': 'linear'}\n",
       "1        random_forest    0.983177                       {'n_estimators': 10}\n",
       "2        decision_tree    0.967753  {'criterion': 'gini', 'splitter': 'best'}\n",
       "3  logistic_regression    0.952369                                   {'C': 5}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X, y)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all these models have a lot of hyperparameters we can use to train them. GridSearchCV utilizes combinations to decide on the best set of hyperparameters under the hood hence experimenting with all of them will be time consuming. Given that our model performance is not that bad, it is best we leave the optimazation here and go with random forest as our classifier. ðŸ––ðŸ‘Š\n",
    "\n",
    "\n",
    "### Best Optimized Model & Indepth Model Performance Evaluation\n",
    "\n",
    "#### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=15)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_model = RandomForestClassifier(n_estimators=10,random_state=15)\n",
    "\n",
    "# training the model using Training data\n",
    "optimal_model.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data =  0.9969135802469136\n"
     ]
    }
   ],
   "source": [
    "# accuracy on training data\n",
    "optimal_X_train_prediction = optimal_model.predict(X_train_final)\n",
    "optimal_training_data_accuracy = accuracy_score(y_train, optimal_X_train_prediction)\n",
    "print('Accuracy on training data = ', optimal_training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data =  0.986046511627907\n"
     ]
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "optimal_X_test_prediction = optimal_model.predict(X_test_final)\n",
    "optimal_test_data_accuracy = accuracy_score(y_test, optimal_X_test_prediction)\n",
    "print('Accuracy on test data = ', optimal_test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears our model has a balanced fit. This notebook was executed several times and each time it was executed both the training accuracy and testing accuracy were not so further off. It is also worth noting that since random forest is a stochastic algorithm this behavior of it having different accuracy scores on different datasets was expected and for that reason we are going to keep this iteration as the last one and evaluate our model with it. Hence, in the future, do not be alarmed when this pipeline is reexecuted and we get different results on accuracy. It is a feature not a bug. ðŸ˜ðŸ˜ƒðŸ˜†ðŸƒâ€â™‚ï¸ðŸƒâ€â™€ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Let us plot a confusion matrix for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x234ea002f48>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(optimal_model, \n",
    "                      X_test_final, \n",
    "                      y_test, \n",
    "                      display_labels=[\"Benign\",\"Malignant\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the model classified 107 (104+3) observations as benign. This classification equates to 97.2% accuracy. 104/107 of those which were picked as benign were correctly classified. For the sensitivity, 108 daignoses where classified as malignant. All the 108 diagnoses were correctly classified, yielding a 100% classification accuracy i.e. (108/108)*100 = 100%\n",
    "\n",
    "\n",
    "\n",
    "To Break this confusion matrix further we have:\n",
    "\n",
    "##### Specificity aka True Negative Rate\n",
    "104 True Negatives (TN): Diagnoses which are benign and correctly classifed as benign\n",
    "\n",
    "3 False Positives (FP): Diagnoses which are benign but were wrongly classfied as malignant\n",
    "\n",
    "Specifity = TN/TN+FP\n",
    "\n",
    "Specificity = 104/104+3\n",
    "\n",
    "Specifity = 0.972 or 97.2%\n",
    "\n",
    "\n",
    "##### Sensitivity\n",
    "108 True Positives (TP): Diagnoses which are malignant and correctly classifed as malignant\n",
    "\n",
    "0 False Negatives (FN): Diagnoses which are malignant but were wrongly classfied as benign\n",
    "\n",
    "Sensitivity = TP/TP+FN\n",
    "\n",
    "Sensitivity = 108/108+0\n",
    "\n",
    "Sensitivity = 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver Operating Characteristic(ROC) & Area Under The Curve (AUC)\n",
    "\n",
    "The Receiver Operator Characteristic (ROC) curve is an evaluation metric for binary classification problems. It is a probability curve that plots the TPR against FPR at various threshold values and essentially separates the â€˜signalâ€™ from the â€˜noiseâ€™. The Area Under the Curve (AUC) is the measure of the ability of a classifier to distinguish between classes and is used as a summary of the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the probabilities of our classes instead of predicting the target labels/classes\n",
    "y_train_score = optimal_model.predict_proba(X_train_final)[:, 1]\n",
    "y_test_score = optimal_model.predict_proba(X_test_final)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability of Predictions\n",
    "A machine learning classification model can be used to predict the actual class of the data point directly or predict its probability of belonging to different classes. The latter gives us more control over the result. We can determine our own threshold to interpret the result of the classifier. This is sometimes more prudent than just building a completely new model!\n",
    "\n",
    "Setting different thresholds for classifying positive class for data points will inadvertently change the Sensitivity and Specificity of the model. And one of these thresholds will probably give a better result than the others, depending on whether we are aiming to lower the number of False Negatives or False Positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (roc_curve, roc_auc_score, auc,classification_report)\n",
    "auc_train = roc_auc_score(y_train, y_train_score)\n",
    "auc_test = roc_auc_score(y_test, y_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Training AUC: 0.9999807098765432\n",
      "      Testing AUC: 0.9942886812045691\n"
     ]
    }
   ],
   "source": [
    "#display AUC score for training and testing\n",
    "print(f\"\"\"\n",
    "      Training AUC: {auc_train}\n",
    "      Testing AUC: {auc_test}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the false positive rate and true positive rate\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_score)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPR tells us what proportion of the negative class got incorrectly classified.\n",
    "\n",
    "TPR tells us what proportion of the positive class got correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When AUC = 1, then the classifier is able to perfectly distinguish between all the benign and the malignant class points correctly. If, however, the AUC had been 0, then the classifier would be predicting all benign as malignant, and all malignant as benign.\n",
    "\n",
    "\n",
    "When 0.5<AUC<1, there is a high chance that the classifier will be able to distinguish the malignant class values from the benign class values. This is so because the classifier is able to detect more numbers of True positives and True negatives than False negatives and False positives.\n",
    "\n",
    "\n",
    "When AUC=0.5, then the classifier is not able to distinguish between malignant and benign class points. Meaning either the classifier is predicting random class or constant class for all the data points.\n",
    "\n",
    "Our AUC score is 0.99 which means our model is a doing a stellar job in differentiating the two classes.The higher the AUC, the better the performance of the model at distinguishing between benign and and malignant classes. But, take this remark with a litle grain of salt. You will know why in a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = optimal_model.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for element in yp:\n",
    "    if element > 0.5: #this threshold can be different\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.99       107\n",
      "         1.0       0.97      1.00      0.99       108\n",
      "\n",
      "    accuracy                           0.99       215\n",
      "   macro avg       0.99      0.99      0.99       215\n",
      "weighted avg       0.99      0.99      0.99       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precision\n",
    "Precision talks about how precise/accurate our model is. Out of those predicted positive,how many of them are actual positive\n",
    "\n",
    "Precision = TP/TP+FP\n",
    "\n",
    "\n",
    "##### Recall  aka Sensitivity aka True Positive Rate\n",
    "Recall calculates how many of the actual positives our model capture through labeling it as Positive (True Positive). Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative. Like in this context. Every life matters. ðŸ¤·â€â™‚ï¸\n",
    "\n",
    "Recall = TP/TP+FN\n",
    "\n",
    "\n",
    "##### F1 Score\n",
    "F1 is a function of Precision and Recall. We need it to seek a balance between Precision and Recall. \n",
    "\n",
    "All in all, this will be a good model if we were interested in idenfying benign diagnoses. It would do a stellar job. However the 1% (based on the f1-score and accuracy) and 3% (recall score for the malignant class) misclassifications could be problamatic. Especially if we do not admistered timely treatements to patients who do have cancer but our model says they are just faking it ðŸ™„. Cancer can be life threatening if not treated early and maliganant tumors can also metastasize to other parts of the body. This is the reason why you had to take the AUC score remarks with a grain of salt. ðŸ™‚\n",
    "\n",
    "\n",
    "### Building a Predictive System\n",
    "\n",
    "Lets export our dataset to a text file to use for our model testing. Remember that we dropped some features when doing feature selection? Great, then we have to export that last modified data frame. This is the same dataset we used for testing our model. Feel free to use your own for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_test_df['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df.to_csv('Breast Cancer Classfication Testing Dataset.txt', header=None, index=None, sep=',', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n",
      "The Breast Cancer is Benign\n"
     ]
    }
   ],
   "source": [
    "input_data = (13.03,82.61,523.8,0.08983,0.03766,0.02562,0.02923,0.1839,1.17,14.16,0.01343,0.01164,13.3,22.81,84.46,545.9,0.09701,0.04619,0.04833,0.05013)\n",
    "\n",
    "# change the input data to a numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the numpy array as we are predicting for one datapoint\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "  print('The Breast cancer is Malignant')\n",
    "\n",
    "else:\n",
    "  print('The Breast Cancer is Benign')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the tested model to a pickle file\n",
    "\n",
    "Model building is complete, lets export it to a pickle file to used by our python FastAPI sever, React Js and React Native Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('breast_cancer_classification_model.pickle','wb') as f:\n",
    "    pickle.dump(optimal_model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
